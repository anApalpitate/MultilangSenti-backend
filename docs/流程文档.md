# 任务流程文档

### 第一阶段：语料准备与预处理

### 1.1语料收集

1. 从公开语料库下载多语言新闻数据
   * MLSUM（德/法/西/土/俄）
   * CC-News(自动化爬虫支持)
   * Sogou新闻(中文)
   * WMT News Commentary
2. 保存格式统一为: `.csv`/`.json`/`.txt`

### 1.2语言识别

* 使用`langdetect`或`fastText`模型自动判断每条新闻的语言
* 在工程上实现自动语言标签标注，如：

```json
{"text": "C'est un scandale politique.", "lang": "fr"}

```

### 1.3 文本预处理

* 对不同语言文本执行标准化清洗：
  * 删除HTML、标点、表情符号等
  * 分词：使用 spaCy、Stanza、nltk（按语言定制）

## 第二阶段：模型接入与情感分析逻辑

### 2.1 多语言模型选型

* 选择 HuggingFace 支持的多语模型：
  * 主模型：`xlm-roberta-base` 或 `xlm-roberta-large`
  * 可选：`nlptown/bert-base-multilingual-uncased-sentiment（已微调）`

### 2.2 情感预测流程

* 针对每条新闻文本，按语言送入模型推理
* 输出为：
  * 情感极性标签（正面 / 中性 / 负面）
  * 或概率分布（softmax）

### 2.3 小语种增强机制（可选增强）

* 若模型原生支持弱，可添加增强策略：
  * Translate-test（小语种翻译为英语再分析）
  * 相似语种迁移（如西语模型迁移葡语）
  * 蒸馏模型训练或微调（可选）

## 第三阶段：系统搭建与前端平台设计

### 3.1 平台结构设计（模块化）

* 构建以下模块
  * 数据上传模块（支持txt/json/csv）
  * 语言识别模块（自动标注语言）
  * 情感分析模块（调用模型）
  * 结果输出模块（标签/概率）
  * 可视化模块（情感分布柱状图/词云）
  * 日志与导出模块（保存CSV/JSON结果）

### 3.2 前端开发

* 使用 Streamlit 或 Gradio 搭建交互界面
* 样例功能包括：
  * 选择/上传文件
  * 显示每条文本的情感判断结果
  * 可视化整体统计图
  * 切换不同语言筛选

### 3.3 后端与接口支持

* 使用 Python（FastAPI ）构建后端API
* 模型通过接口处理推理任务
* 所有分析与预测逻辑封装为模块或服务

## 总结：平台实现的核心技术路径

```latex
[语料收集]
   ↓
[语言识别]
   ↓
[多语预处理]
   ↓
[模型推理：XLM-R]
   ↓
[情感分析结果输出]
   ↓
[可视化 + 导出 + 用户交互界面]

```